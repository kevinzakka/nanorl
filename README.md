# nanorl

A tiny reinforcement learning codebase for continuous control, built on top of [JAX](https://github.com/google/jax). Minimal, self-contained and research-friendly. Inspired by Ilya Kostrikov's [jaxrl](https://github.com/ikostrikov/jaxrl).

## Installation

1. `pip install --upgrade "jax[cuda]==0.3.25" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html`
2. `git clone https://github.com/kevinzakka/nanorl && cd nanorl`
3. `pip install -r requirements.txt`
4. `pip install -e ".[all]"`
